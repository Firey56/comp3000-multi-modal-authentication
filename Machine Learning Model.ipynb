{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model\n",
    "\n",
    "Machine Learning Model for user sign in - this takes in a list of keystroke patterns of the attempted logins from the user. It trains the model each attempt and returns a confidence score based on the new provided keystroke pattern vs what the system would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This work will be annotated using the Better Comments Extension\n",
    "#! This is for notes and for things that need to be worked on, mainly error handling\n",
    "#? This is for questioning if this is finished or needs adding/reworking\n",
    "#*This text will highlight, this will mainly be for notes\n",
    "#//This should cross out any lines of code that are no longer needed or used during testing.\n",
    "#TODO This is for annotating work that needs to be implemented.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "import json\n",
    "import pandas\n",
    "import random\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyodbc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all our global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1651 0.8349]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sys\n",
    "import json\n",
    "import pandas\n",
    "import random\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pyodbc\n",
    "\n",
    "\n",
    "array_2d = []\n",
    "columnAverages = []\n",
    "column_arrays = []#Array for each keyset (this will take the timing between keystroke 1 and 2 of every sample)\n",
    "standard_deviations = []#Create our standard deviation arrays\n",
    "poisonSamples = []\n",
    "numberOfPoisonSamplesWanted = 0\n",
    "concatenated_strings = []\n",
    "insertedData = \"Keystroke,123,Keystroke,110,Keystroke,169,Keystroke,237,Keystroke,126,Keystroke,135,Keystroke,174,Keystroke,170,Keystroke,120,Keystroke,78,Keystroke,92,Keystroke\"\n",
    "###########################################################\n",
    "#Read the objects\n",
    "###########################################################\n",
    "\n",
    "#columnNames = [\"PatternNumber\", \"UserID\", \"Keystroke\", \"Expected\"]\n",
    "#fileLocation = \"KeystrokeExcel.xlsx\"\n",
    "#data = pandas.read_excel(\"KeystrokeExcel.xlsx\", names = columnNames)\n",
    "#dataFrame = pandas.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "connectionString = pyodbc.connect(\n",
    "    driver=\"ODBC Driver 17 for SQL Server\",\n",
    "    server=\"dissi-database.c32y6sk2evqy.eu-west-2.rds.amazonaws.com\",\n",
    "    database=\"Dissertation\",\n",
    "    uid=\"admin\",\n",
    "    pwd=\"V4F^E2Tt#M#p#bjj\"\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = connectionString.cursor()\n",
    "# Define the SELECT query\n",
    "#query = \"SELECT Keystrokes, Expected FROM [dissertation].[alex]\"\n",
    "username = \"alex\"\n",
    "cursor.execute(\"EXEC dissertation.GetKeystrokes @TableName=?\", (username))\n",
    "# Execute the query\n",
    "# Fetch all rows\n",
    "rows = cursor.fetchall()\n",
    "allKeystrokeDataFrame = pandas.DataFrame(columns = [\"Keystroke\", \"Expected\"])\n",
    "#print(allKeystrokeDataFrame)\n",
    "    #print(eachRow)\n",
    "# Assuming eachRow is a list of value\n",
    "array_2d = []\n",
    "# Iterate over the rows\n",
    "for eachRow in rows:\n",
    "    # Convert eachRow to a numpy array\n",
    "    eachRow = numpy.array(eachRow)\n",
    "    # Append the row to the array\n",
    "    array_2d.append(eachRow)\n",
    "    \n",
    "# Convert the list to a numpy array for further processing\n",
    "array_2d = numpy.array(array_2d)\n",
    "#print(array_2d)\n",
    "\n",
    "# Convert the 2D array into a DataFrame\n",
    "df = pandas.DataFrame(array_2d, columns=[\"Keystroke\", \"Expected\"])\n",
    "\n",
    "# Print the DataFrame\n",
    "#print(df)\n",
    "cursor.close()\n",
    "connectionString.close()\n",
    "\n",
    "#############################################################\n",
    "#At this point, we have read in our data and have it in a dataframe\n",
    "############################################################\n",
    "array_2d = [row.split() for row in df['Keystroke']]\n",
    "#print(array_2d)\n",
    "def remove_keystrokes_and_commas(text):\n",
    "    words = text.split(',')\n",
    "    words = [word for word in words if word != 'Keystroke']\n",
    "    return ','.join(words)\n",
    "\n",
    "\n",
    "def row_to_2d_array(currentSelection):\n",
    "    # Split the row by commas and create a list\n",
    "    elements = currentSelection.split(',')\n",
    "    # Remove 'Keystroke' from the list\n",
    "    elements = [float(e) for e in elements if e != 'Keystroke']\n",
    "    # Convert list into a 2D array where each element is a list\n",
    "    return [elements]\n",
    "\n",
    "array_2d = numpy.concatenate(df['Keystroke'].apply(row_to_2d_array).tolist(), axis=0)\n",
    "\n",
    "#############################################################\n",
    "#Finished 2D Array Creation\n",
    "#############################################################\n",
    "\n",
    "\n",
    "#############################################################\n",
    "#Creating standard deviations\n",
    "#############################################################\n",
    "\n",
    "#Calculate average for each timing per pattern\n",
    "for col_index in range(len(array_2d[0])):\n",
    "    # Initialize sum and count for the current column\n",
    "    col_sum = 0\n",
    "    col_count = 0\n",
    "    # Iterate over rows\n",
    "    for row in array_2d:\n",
    "        # Add element from the current column to sum\n",
    "        col_sum += row[col_index]\n",
    "        # Increment count\n",
    "        col_count += 1\n",
    "    # Calculate average for the current column\n",
    "    col_average = col_sum / col_count\n",
    "    # Append the average to the list of column averages\n",
    "    columnAverages.append(col_average)\n",
    "\n",
    "#Create X amount of arrays of Y length depending on samples\n",
    "\n",
    "#Calculate standard deviations\n",
    "\n",
    "# Iterate over columns\n",
    "#For loop to create new arrays that have our keyset timings\n",
    "for col_index in range(len(array_2d[0])):\n",
    "    # Initialize an empty array for the current column\n",
    "    column_array = []\n",
    "    # Iterate over rows\n",
    "    for row in array_2d:\n",
    "        # Append the element from the current column to the column array\n",
    "        column_array.append(row[col_index])\n",
    "    # Append the column array to the list of column arrays\n",
    "    column_arrays.append(column_array)\n",
    "\n",
    "#############################################################\n",
    "#Loop to generate our standard deviation for each timeset\n",
    "##########################################################\n",
    "for i in range(len(column_arrays)):\n",
    "    standard_deviations.append(numpy.std(column_arrays[i]))\n",
    "\n",
    "#Have a function that iterates for each sample generation\n",
    "numberOfPoisonSamplesWanted = len(array_2d)*3\n",
    "for i in range(numberOfPoisonSamplesWanted):\n",
    "    newSample = []\n",
    "    for j in range(len(columnAverages)):\n",
    "        newRandom = random.randint(-2,2)\n",
    "        noise = random.randint(-20,20)\n",
    "        if(columnAverages[j] + newRandom*standard_deviations[j] + noise <= 0):\n",
    "            newSample.append(100)\n",
    "        else:\n",
    "            newSample.append(round(columnAverages[j] + newRandom*standard_deviations[j] + noise))\n",
    "        #print(newSample)\n",
    "        j+= 1\n",
    "    #print(newSample)\n",
    "    poisonSamples.append(newSample)\n",
    "    \n",
    "    i+= 1\n",
    "df['Keystroke'] = pandas.concat([df['Keystroke'],pandas.Series(poisonSamples)], ignore_index=True)\n",
    "\n",
    "concatenated_strings = [','.join(map(str, row)) for row in poisonSamples]\n",
    "newData = {\n",
    "    'Keystroke': concatenated_strings,\n",
    "    'Expected': 1\n",
    "    }\n",
    "legitimateKeystrokeData = df['Keystroke'].tolist()\n",
    "legitimateExpectedData = [0] * len(array_2d)\n",
    "\n",
    "poisonedKeystrokeData = concatenated_strings\n",
    "poisonedExpectedData = [1] * numberOfPoisonSamplesWanted\n",
    "\n",
    "combined_keystrokes = legitimateKeystrokeData + poisonedKeystrokeData\n",
    "combined_expected = legitimateExpectedData + poisonedExpectedData\n",
    "\n",
    "finalDataFrame = pandas.DataFrame({\n",
    "    'Keystroke': combined_keystrokes,\n",
    "    'Expected': combined_expected\n",
    "})\n",
    "\n",
    "finalDataFrame['Keystroke'] = finalDataFrame['Keystroke'].apply(remove_keystrokes_and_commas)\n",
    "new_array_2d = finalDataFrame.to_numpy()\n",
    "#print(new_array_2d)\n",
    "#print(new_array_2d)\n",
    "inputs = []\n",
    "targets = []\n",
    "for idx, row in enumerate(new_array_2d):\n",
    "    row_data = row[0].split(',')  # Split the string by comma to get individual features\n",
    "    #print(row_data)\n",
    "    try:\n",
    "        inputs.append([float(val) for val in row_data if val.strip()])  # Convert features to float and append to features list\n",
    "        targets.append(row[1])  # Append target variable to targets list\n",
    "        #print(targets)\n",
    "    except ValueError:#Incase something goes wrong with creating our targets for the model\n",
    "        print(\"Non-numeric value found in row, skipping...\")\n",
    "        print(f\"Non-numeric value found in row {idx}, skipping...\")\n",
    "\n",
    "#print(features)\n",
    "x = numpy.array(inputs)\n",
    "y = numpy.array(targets)\n",
    "#scaler = MinMaxScaler()\n",
    "#scaled = scaler.fit_transform(inputs)\n",
    "#print(scaled)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y)\n",
    "\n",
    "def trainClassifier(reshapedInsertedData):\n",
    "    #print(\"Inside classifier\")\n",
    "    classifierRandomForest = RandomForestClassifier(n_estimators=10000, max_depth=40, bootstrap=True, max_features=None)\n",
    "    classifierRandomForest.fit(X_train, Y_train)\n",
    "    accuracy = classifierRandomForest.score(X_test, Y_test)\n",
    "    #print(\"Accuracy on test set:\", accuracy)\n",
    "    #definitelyFakeData = [94,46,174,215,142,91,62,159,155,91,31,107]\n",
    "    #new_sample_array = numpy.array(definitelyFakeData).reshape(1,-1)\n",
    "    prediction = classifierRandomForest.predict(reshapedInsertedData)\n",
    "    estimates = classifierRandomForest.predict_proba(reshapedInsertedData)\n",
    "    #print(prediction)\n",
    "    print(estimates)\n",
    "    confidenceScore = 0\n",
    "    if prediction == 0:\n",
    "        confidenceScore = estimates[0,0]\n",
    "    else:\n",
    "        confidenceScore = estimates[0,1]\n",
    "\n",
    "    #print(\"Predicted Value: \" + str(prediction) + \" with Confidence Score \" + str(confidenceScore*100) + \"%\")\n",
    "    #if estimates[0,0] >= 0.65:\n",
    "    #    print(\"The user has reached the threshold for login at confidence score of: \" + str(estimates[0,0]*100) + \"%\")\n",
    "\n",
    "#updatedInsert = remove_keystrokes_and_commas(insertedData)\n",
    "#updatedInsertArray = row_to_2d_array(updatedInsert)\n",
    "\n",
    "#print(insertedData)\n",
    "insertedData = insertedData.split(',')\n",
    "for word in insertedData:\n",
    "    if word == \"Keystroke\":\n",
    "        insertedData.remove('Keystroke')\n",
    "reshapedInsertedData = numpy.array(insertedData).reshape(1,-1)\n",
    "\n",
    "trainClassifier(reshapedInsertedData)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
